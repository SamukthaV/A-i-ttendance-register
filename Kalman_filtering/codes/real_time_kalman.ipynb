{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe8S9rBOhJmvWcF5PMSkfo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamukthaV/A-i-ttendance-register/blob/master/Kalman_filtering/codes/real_time_kalman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es0fMBOTqg1o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use JavaScript to create video stream input\n",
        "def start_camera():\n",
        "    js_code = '''\n",
        "    const video = document.createElement('video');\n",
        "    document.body.appendChild(video);\n",
        "    video.style.position = 'fixed';\n",
        "    video.style.top = '0';\n",
        "    video.style.left = '0';\n",
        "    video.style.zIndex = '1000';\n",
        "\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {\n",
        "        video.srcObject = stream;\n",
        "        video.play();\n",
        "    });\n",
        "\n",
        "    var video_url = new URL(video.srcObject.getTracks()[0].getSettings().deviceId);\n",
        "    video_url.pathname.slice(6);\n",
        "    '''\n",
        "    return eval_js(js_code)\n",
        "\n",
        "# Use OpenCV to capture and display video stream\n",
        "def capture_camera(camera_id):\n",
        "    video = cv2.VideoCapture(camera_id)\n",
        "    try:\n",
        "        while True:\n",
        "            _, frame = video.read()\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            display.display(frame)\n",
        "            display.clear_output(wait=True)\n",
        "\n",
        "            # Check for user interrupt (stop button)\n",
        "            if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' key to stop\n",
        "                break\n",
        "    finally:\n",
        "        video.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# Start camera and get camera ID\n",
        "camera_id = start_camera()\n",
        "\n",
        "# Capture and display video stream\n",
        "capture_camera(camera_id)"
      ],
      "metadata": {
        "id": "Htv5qQVjrWjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install opencv-python"
      ],
      "metadata": {
        "id": "HWEY4RIztBi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ff829c-ec3e-4877-d52d-7767d18748eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKM5QpUKwySO",
        "outputId": "830de9ce-7c5f-496e-9b7e-333068f15c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16260, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (131/131), done.\u001b[K\n",
            "remote: Total 16260 (delta 66), reused 72 (delta 26), pack-reused 16103\u001b[K\n",
            "Receiving objects: 100% (16260/16260), 15.01 MiB | 23.22 MiB/s, done.\n",
            "Resolving deltas: 100% (11102/11102), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install ultralytics"
      ],
      "metadata": {
        "id": "8KSWmgGlyDvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch\n",
        "from IPython.display import display, Image\n",
        "from yolov5 import detect\n",
        "from google.colab.output import eval_js"
      ],
      "metadata": {
        "id": "sB3Yad32u_Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "\n",
        "# Use JavaScript to create video stream input\n",
        "def start_camera():\n",
        "    js_code = '''\n",
        "    const video = document.createElement('video');\n",
        "    document.body.appendChild(video);\n",
        "    video.style.position = 'fixed';\n",
        "    video.style.top = '0';\n",
        "    video.style.left = '0';\n",
        "    video.style.zIndex = '1000';\n",
        "\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {\n",
        "        video.srcObject = stream;\n",
        "        video.play();\n",
        "    });\n",
        "\n",
        "    var video_url = new URL(video.srcObject.getTracks()[0].getSettings().deviceId);\n",
        "    video_url.pathname.slice(6);\n",
        "    '''\n",
        "    return eval_js(js_code)\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5:master', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Use YOLOv5 to perform real-time object detection with bounding boxes\n",
        "def detect_objects(camera_id=0, confidence_threshold=0.5):\n",
        "    # Open camera\n",
        "    cap = cv2.VideoCapture(camera_id)\n",
        "    try:\n",
        "        while True:\n",
        "            _, frame = cap.read()\n",
        "\n",
        "            # Perform object detection\n",
        "            results = model(frame)\n",
        "\n",
        "            # Draw bounding boxes on the frame\n",
        "            frame_with_boxes = results.render()[0]\n",
        "            display(Image(data=cv2.imencode('.jpg', frame_with_boxes)[1].tobytes()))\n",
        "\n",
        "            # Check for user interrupt (stop button)\n",
        "            if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' key to stop\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# Start camera and get camera ID\n",
        "camera_id = start_camera()\n",
        "\n",
        "# Detect objects in real-time with bounding boxes\n",
        "detect_objects(camera_id)"
      ],
      "metadata": {
        "id": "tJvyfSwLxRqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rTfteuESx6cQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}